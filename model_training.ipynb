{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3BB3_XB_y2Qg",
   "metadata": {
    "id": "3BB3_XB_y2Qg"
   },
   "source": [
    "# Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mMdO9c4mU7SZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 2509,
     "status": "ok",
     "timestamp": 1767707732569,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "mMdO9c4mU7SZ",
    "outputId": "2972e180-6d61-4df4-d797-9764f09a038e"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "bundle = joblib.load(\"tabular_preprocessed.joblib\")\n",
    "\n",
    "X_train = bundle[\"X_train_final\"]\n",
    "y_train = bundle[\"y_train\"]\n",
    "X_val = bundle[\"X_val_final\"]\n",
    "y_val = bundle[\"y_val\"]\n",
    "train_ids = bundle[\"train_ids\"]\n",
    "val_ids = bundle[\"val_ids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "okY73iXeU7LI",
   "metadata": {
    "id": "okY73iXeU7LI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"train_config.json\") as f:\n",
    "    cfg = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rIIlWKwpy6yC",
   "metadata": {
    "id": "rIIlWKwpy6yC",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MultiModalRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ONLAdbaZU7aK",
   "metadata": {
    "id": "ONLAdbaZU7aK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, image_dir, tabular_data, ids, targets=None, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.tabular_data = tabular_data\n",
    "        self.ids = ids\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, f\"{sample_id}.png\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tabular = torch.tensor(self.tabular_data[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "            return image, tabular, target\n",
    "\n",
    "        return image, tabular\n",
    "\n",
    "\n",
    "class TabularEncoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class MultimodalRegressor(nn.Module):\n",
    "    def __init__(self, image_encoder, tabular_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_encoder = image_encoder\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(512 + tabular_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, tabular):\n",
    "        img_feat = self.image_encoder(image)\n",
    "        x = torch.cat([img_feat, tabular], dim=1)\n",
    "        return self.regressor(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ehLhvXlTlx5r",
   "metadata": {
    "id": "ehLhvXlTlx5r"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "val_img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K3ppdx45U7Ar",
   "metadata": {
    "id": "K3ppdx45U7Ar"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = MultimodalDataset(\n",
    "    image_dir=cfg[\"train_image_dir\"],\n",
    "    tabular_data=X_train,\n",
    "    ids=train_ids,\n",
    "    targets=y_train,\n",
    "    transform=train_img_transform\n",
    ")\n",
    "\n",
    "val_dataset = MultimodalDataset(\n",
    "    image_dir=cfg[\"train_image_dir\"],\n",
    "    tabular_data=X_val,\n",
    "    ids=val_ids,\n",
    "    targets=y_val,\n",
    "    transform=val_img_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eby2ir26nc7H",
   "metadata": {
    "id": "eby2ir26nc7H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZgUsQ11kpNzq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1767707763078,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "ZgUsQ11kpNzq",
    "outputId": "ba74180a-41d8-47f3-f4d7-a59b9f0b061c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['num_tabular_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y6bgaP8Bl7Ff",
   "metadata": {
    "id": "y6bgaP8Bl7Ff"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "\n",
    "\n",
    "model = MultimodalRegressor(\n",
    "    image_encoder=resnet,\n",
    "    tabular_dim=cfg[\"num_tabular_features\"]\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N7yVIBtkl64C",
   "metadata": {
    "id": "N7yVIBtkl64C"
   },
   "outputs": [],
   "source": [
    "for param in model.image_encoder.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dqm3KYVyl6qW",
   "metadata": {
    "id": "Dqm3KYVyl6qW"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jj9OIdVrql-H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9877,
     "status": "ok",
     "timestamp": 1767642791953,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "Jj9OIdVrql-H",
    "outputId": "7dea2fdf-fa89-4510-871c-5f6ec0de2921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape   : torch.Size([32, 3, 224, 224])\n",
      "Tabular shape : torch.Size([32, 23])\n",
      "Target shape  : torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "images, tabular, targets = next(iter(train_loader))\n",
    "\n",
    "print(\"Image shape   :\", images.shape)\n",
    "print(\"Tabular shape :\", tabular.shape)\n",
    "print(\"Target shape  :\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VlrRHtr5onGi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13326,
     "status": "ok",
     "timestamp": 1767641965725,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "VlrRHtr5onGi",
    "outputId": "d3151f9b-1f09-45a6-a446-a0cbb1a61e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "images, tabular, targets = next(iter(train_loader))\n",
    "\n",
    "images = images.to(device)\n",
    "tabular = tabular.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(images, tabular)\n",
    "\n",
    "print(preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7PnPIC1Jom7S",
   "metadata": {
    "id": "7PnPIC1Jom7S"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, tabular, targets in loader:\n",
    "        images = images.to(device)\n",
    "        tabular = tabular.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images, tabular).squeeze(1)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CC5uqc4arTnE",
   "metadata": {
    "id": "CC5uqc4arTnE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, tabular, targets in loader:\n",
    "            images = images.to(device)\n",
    "            tabular = tabular.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images, tabular).squeeze(1)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            trues.append(targets.cpu().numpy())\n",
    "\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "\n",
    "    mse = mean_squared_error(trues, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    val_r2 = r2_score(trues, preds)\n",
    "\n",
    "    return total_loss / len(loader.dataset), rmse, val_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M4dRjgQAzDC1",
   "metadata": {
    "id": "M4dRjgQAzDC1"
   },
   "source": [
    "# First Stage Training (Frozen CNN layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bd5f6-c0b4-4eff-80cc-72607351a65b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13197173,
     "status": "ok",
     "timestamp": 1767656146443,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "556bd5f6-c0b4-4eff-80cc-72607351a65b",
    "outputId": "b254b894-941f-4f5d-d338-69c572940256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Train loss: 154.1866 | Val RMSE: 10.9416 | Val R²: -432.8349\n",
      "Epoch [2/5] | Train loss: 72.0984 | Val RMSE: 5.2077 | Val R²: -97.2784\n",
      "Epoch [3/5] | Train loss: 11.1339 | Val RMSE: 1.1867 | Val R²: -4.1032\n",
      "Epoch [4/5] | Train loss: 4.7092 | Val RMSE: 0.7229 | Val R²: -0.8940\n",
      "Epoch [5/5] | Train loss: 4.1394 | Val RMSE: 0.7486 | Val R²: -1.0307\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47KcULJ2zSsp",
   "metadata": {
    "id": "47KcULJ2zSsp",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# First stage Unfrozen layer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yhMFrn6xuK3q",
   "metadata": {
    "id": "yhMFrn6xuK3q"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d4700-5249-4682-b6c3-c18227bcc032",
   "metadata": {
    "id": "006d4700-5249-4682-b6c3-c18227bcc032"
   },
   "outputs": [],
   "source": [
    "for param in model.image_encoder.layer4.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1f2c4-8092-419c-a061-2775aebe4c3d",
   "metadata": {
    "id": "24b1f2c4-8092-419c-a061-2775aebe4c3d"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697968e-9218-42ff-855c-5a2034a8e899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11310662,
     "status": "ok",
     "timestamp": 1767667457212,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "9697968e-9218-42ff-855c-5a2034a8e899",
    "outputId": "e2ec0ff2-624d-46ec-c718-1068e0a20592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Train loss: 3.6079 | Val RMSE: 0.5834 | Val R²: -0.2333\n",
      "Epoch [2/5] | Train loss: 3.4037 | Val RMSE: 0.5011 | Val R²: 0.0900\n",
      "Epoch [3/5] | Train loss: 3.2972 | Val RMSE: 0.4285 | Val R²: 0.3346\n",
      "Epoch [4/5] | Train loss: 2.9724 | Val RMSE: 0.4217 | Val R²: 0.3555\n",
      "Epoch [5/5] | Train loss: 2.9619 | Val RMSE: 0.6140 | Val R²: -0.3660\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kFCO-ARUzjkl",
   "metadata": {
    "id": "kFCO-ARUzjkl",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Second Stage Unfrozen Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e805433-d777-49c2-8748-673a77e46b28",
   "metadata": {
    "id": "5e805433-d777-49c2-8748-673a77e46b28"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6195a2-49f6-4997-aef4-2c424e552014",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11169409,
     "status": "ok",
     "timestamp": 1767678628691,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "6c6195a2-49f6-4997-aef4-2c424e552014",
    "outputId": "ea14ad37-1342-4000-ab76-497595e796af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Train loss: 2.9322 | Val RMSE: 0.5410 | Val R²: -0.0605\n",
      "Epoch [2/5] | Train loss: 2.7045 | Val RMSE: 0.8871 | Val R²: -1.8517\n",
      "Epoch [3/5] | Train loss: 2.5676 | Val RMSE: 0.4042 | Val R²: 0.4080\n",
      "Epoch [4/5] | Train loss: 2.4418 | Val RMSE: 0.4390 | Val R²: 0.3018\n",
      "Epoch [5/5] | Train loss: 2.3865 | Val RMSE: 0.3423 | Val R²: 0.5754\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hkT9scUIzqT_",
   "metadata": {
    "id": "hkT9scUIzqT_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Third Stage Unfrozen Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dxTeWP63gkA4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1767707822177,
     "user": {
      "displayName": "Anirudh",
      "userId": "08093268449357160353"
     },
     "user_tz": -330
    },
    "id": "dxTeWP63gkA4",
    "outputId": "26a97c09-41b8-4134-f1c9-c507256791a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\"best_multimodal_model.pt\", map_location=device)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cJLVpjZeH9wI",
   "metadata": {
    "id": "cJLVpjZeH9wI"
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-7,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R4mQApQbgkWY",
   "metadata": {
    "id": "R4mQApQbgkWY"
   },
   "outputs": [],
   "source": [
    "\n",
    "for param in model.image_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "for param in model.image_encoder.layer4.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CESv-Igrgkrw",
   "metadata": {
    "id": "CESv-Igrgkrw",
    "outputId": "5b1d505f-9aa1-4d1c-848e-c3eff8af40eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Train loss: 2.3119 | Val RMSE: 0.2930 | Val R²: 0.6889\n",
      "Epoch [2/5] | Train loss: 2.3096 | Val RMSE: 0.2885 | Val R²: 0.6985\n",
      "Epoch [3/5] | Train loss: 2.3390 | Val RMSE: 0.2942 | Val R²: 0.6864\n",
      "Epoch [4/5] | Train loss: 2.2764 | Val RMSE: 0.2936 | Val R²: 0.6877\n",
      "Epoch [5/5] | Train loss: 2.3880 | Val RMSE: 0.2996 | Val R²: 0.6748\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_rmse = 0.2963\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IDABKLX-z75-",
   "metadata": {
    "id": "IDABKLX-z75-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fourth Stage Unfrozen Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989be6e",
   "metadata": {
    "id": "4989be6e"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.3,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee424c",
   "metadata": {
    "id": "77ee424c",
    "outputId": "83c0253f-f895-47f6-fb45-11daa11763be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train loss: 2.2624 | Val RMSE: 0.2968 | Val R²: 0.6808\n",
      "Epoch [2/10] | Train loss: 2.2817 | Val RMSE: 0.2948 | Val R²: 0.6852\n",
      "Epoch [3/10] | Train loss: 2.2885 | Val RMSE: 0.2911 | Val R²: 0.6930\n",
      "Epoch [4/10] | Train loss: 2.2648 | Val RMSE: 0.2872 | Val R²: 0.7011\n",
      "Epoch [5/10] | Train loss: 2.1773 | Val RMSE: 0.2845 | Val R²: 0.7066\n",
      "Epoch [6/10] | Train loss: 2.3170 | Val RMSE: 0.2941 | Val R²: 0.6865\n",
      "Epoch [7/10] | Train loss: 2.3450 | Val RMSE: 0.2818 | Val R²: 0.7122\n",
      "Epoch [8/10] | Train loss: 2.3624 | Val RMSE: 0.2808 | Val R²: 0.7142\n",
      "Epoch [9/10] | Train loss: 2.3321 | Val RMSE: 0.2902 | Val R²: 0.6949\n",
      "Epoch [10/10] | Train loss: 2.3236 | Val RMSE: 0.2913 | Val R²: 0.6925\n",
      "Early stopping triggered at epoch 10 (Val RMSE increased for 2 consecutive epochs)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "best_rmse = 0.2885\n",
    "rmse_increase_count = 0\n",
    "prev_val_rmse = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n",
    "\n",
    "    if prev_val_rmse is not None:\n",
    "        if val_rmse > prev_val_rmse:\n",
    "            rmse_increase_count += 1\n",
    "        else:\n",
    "            rmse_increase_count = 0\n",
    "\n",
    "        if rmse_increase_count >= 2:\n",
    "            print(\n",
    "                f\"Early stopping triggered at epoch {epoch+1} \"\n",
    "                f\"(Val RMSE increased for 2 consecutive epochs)\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    prev_val_rmse = val_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1t5Kq7y0CBE",
   "metadata": {
    "id": "o1t5Kq7y0CBE",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Final Stage Unfrozen Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5ea23",
   "metadata": {
    "id": "8da5ea23"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-6,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.3,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9612fae",
   "metadata": {
    "id": "f9612fae",
    "outputId": "1fa9a70b-4d93-479d-f29f-cdf47f9330a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train loss: 2.3809 | Val RMSE: 0.2842 | Val R²: 0.7072\n",
      "Epoch [2/10] | Train loss: 2.3025 | Val RMSE: 0.2886 | Val R²: 0.6982\n",
      "Epoch [3/10] | Train loss: 2.3031 | Val RMSE: 0.2836 | Val R²: 0.7086\n",
      "Epoch [4/10] | Train loss: 2.2679 | Val RMSE: 0.2803 | Val R²: 0.7153\n",
      "Epoch [5/10] | Train loss: 2.2579 | Val RMSE: 0.2826 | Val R²: 0.7105\n",
      "Epoch [6/10] | Train loss: 2.3446 | Val RMSE: 0.2834 | Val R²: 0.7090\n",
      "Early stopping triggered at epoch 6 (Val RMSE increased for 2 consecutive epochs)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "best_rmse = 0.2\n",
    "rmse_increase_count = 0\n",
    "prev_val_rmse = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_rmse, val_r2 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_rmse)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "        f\"Train loss: {train_loss:.4f} | \"\n",
    "        f\"Val RMSE: {val_rmse:.4f} | \"\n",
    "        f\"Val R²: {val_r2:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"best_multimodal_model.pt\")\n",
    "\n",
    "    if prev_val_rmse is not None:\n",
    "        if val_rmse > prev_val_rmse:\n",
    "            rmse_increase_count += 1\n",
    "        else:\n",
    "            rmse_increase_count = 0\n",
    "\n",
    "        if rmse_increase_count >= 2:\n",
    "            print(\n",
    "                f\"Early stopping triggered at epoch {epoch+1} \"\n",
    "                f\"(Val RMSE increased for 2 consecutive epochs)\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    prev_val_rmse = val_rmse\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3BB3_XB_y2Qg",
    "rIIlWKwpy6yC",
    "M4dRjgQAzDC1",
    "47KcULJ2zSsp",
    "kFCO-ARUzjkl",
    "hkT9scUIzqT_",
    "IDABKLX-z75-",
    "o1t5Kq7y0CBE"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
